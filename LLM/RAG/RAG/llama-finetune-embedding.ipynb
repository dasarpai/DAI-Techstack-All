{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ZOetxjjWf345G_zSkJDZzhdl9b8Ov8gb","authorship_tag":"ABX9TyPk9HNPQ7yM6EUSN3Y9FKUc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0390966c709b4a15a92a0cd13acb374b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c245bb3925cc4c59b850c7153c8e6f31","IPY_MODEL_2cb0cf03310a4e689d3190e1007be43b","IPY_MODEL_6802f96bc5ef46d484e4554100187075"],"layout":"IPY_MODEL_8dad215942d6485f991749d19ede3473"}},"c245bb3925cc4c59b850c7153c8e6f31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90896cd70a984bbea18b7441b8924262","placeholder":"​","style":"IPY_MODEL_39de88493f334050ae78e4827c59d545","value":"Parsing documents into nodes: 100%"}},"2cb0cf03310a4e689d3190e1007be43b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8bb7710b2264612a08e587f39b886d9","max":238,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e92218332f44865a04f0b0a6ddf4788","value":238}},"6802f96bc5ef46d484e4554100187075":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_360918537e124950b33f24d6eb66a7b9","placeholder":"​","style":"IPY_MODEL_5270af6fd9944d2f9fb6b0daebcdd3de","value":" 238/238 [00:00&lt;00:00, 344.57it/s]"}},"8dad215942d6485f991749d19ede3473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90896cd70a984bbea18b7441b8924262":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39de88493f334050ae78e4827c59d545":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8bb7710b2264612a08e587f39b886d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e92218332f44865a04f0b0a6ddf4788":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"360918537e124950b33f24d6eb66a7b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5270af6fd9944d2f9fb6b0daebcdd3de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9f91737dc5d4abc86d767374279caad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36349cf3841c4236b6759ea69d353bb6","IPY_MODEL_d3c8e46d2ed543a48f2c860aeba95cdb","IPY_MODEL_ef3b1ca40fb34644a2230a2f64ea3326"],"layout":"IPY_MODEL_7429185a4ff04dbcb1681da88deb0038"}},"36349cf3841c4236b6759ea69d353bb6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84ba55587f20495aafc35f639403b16f","placeholder":"​","style":"IPY_MODEL_81af2e25d01e487793c6058c4d16cdba","value":"Parsing documents into nodes: 100%"}},"d3c8e46d2ed543a48f2c860aeba95cdb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_368295407d0643349f17b955fe5a72fd","max":307,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f773de2fa4244b28720db3dcd18c785","value":307}},"ef3b1ca40fb34644a2230a2f64ea3326":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39062f243b5a449db48af21cd4d84c89","placeholder":"​","style":"IPY_MODEL_40a7fde3b39e4bbb8313b7c4079ab6d0","value":" 307/307 [00:00&lt;00:00, 467.47it/s]"}},"7429185a4ff04dbcb1681da88deb0038":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84ba55587f20495aafc35f639403b16f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81af2e25d01e487793c6058c4d16cdba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"368295407d0643349f17b955fe5a72fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f773de2fa4244b28720db3dcd18c785":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39062f243b5a449db48af21cd4d84c89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40a7fde3b39e4bbb8313b7c4079ab6d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!ssh-keygen -t rsa -b 4096 -C hari.prasad@vedavit-ps.com -f /content/drive/MyDrive/config/colab_ssh_key"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NsPHeWKvDFPk","executionInfo":{"status":"ok","timestamp":1693308744290,"user_tz":-330,"elapsed":24972,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"ae33a8dc-7c78-4414-b9ea-5263f4d8534e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating public/private rsa key pair.\n","Enter passphrase (empty for no passphrase): \n","Enter same passphrase again: \n","Your identification has been saved in /content/drive/MyDrive/config/colab_ssh_key\n","Your public key has been saved in /content/drive/MyDrive/config/colab_ssh_key.pub\n","The key fingerprint is:\n","SHA256:xyoPZOFGQzs/cANTJiZN9q6J36Ar9e3XE7gkCwUI0qs hari.prasad@vedavit-ps.com\n","The key's randomart image is:\n","+---[RSA 4096]----+\n","|.....+O.o        |\n","| .. .=oB         |\n","|   .  B.+        |\n","|  .  o O.o       |\n","| .    =.S o.     |\n","|E   .=.o.+o .    |\n","|   ...*o.+ o .   |\n","|  .  o.*o o o    |\n","|   .o...+.   .   |\n","+----[SHA256]-----+\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RO48OUzEBl6s","executionInfo":{"status":"ok","timestamp":1693308952274,"user_tz":-330,"elapsed":456,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"dfb01e5e-17b4-456f-f428-d8ec2338cf4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'llama_index'...\n","Host key verification failed.\r\n","fatal: Could not read from remote repository.\n","\n","Please make sure you have the correct access rights\n","and the repository exists.\n"]}],"source":["!git clone git@github.com:jerryjliu/llama_index"]},{"cell_type":"code","source":["!git clone https://github.com/jerryjliu/llama_index.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZbhoVA-FRDr","executionInfo":{"status":"ok","timestamp":1693309028621,"user_tz":-330,"elapsed":8223,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"d96eefb4-2c63-4a2f-df2a-1c01bf4950ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'llama_index'...\n","remote: Enumerating objects: 27442, done.\u001b[K\n","remote: Counting objects: 100% (6038/6038), done.\u001b[K\n","remote: Compressing objects: 100% (1248/1248), done.\u001b[K\n","remote: Total 27442 (delta 5317), reused 4959 (delta 4785), pack-reused 21404\u001b[K\n","Receiving objects: 100% (27442/27442), 61.56 MiB | 17.75 MiB/s, done.\n","Resolving deltas: 100% (18992/18992), done.\n"]}]},{"cell_type":"code","source":["#!git clone git@github.com:run-llama/finetune-embedding.git\n","!git clone https://github.com/run-llama/finetune-embedding.git\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rm95KHgLFYAL","executionInfo":{"status":"ok","timestamp":1693309230853,"user_tz":-330,"elapsed":482,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"d5d9a401-d2cd-4652-9ed7-1ee8dd3f79ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'finetune-embedding'...\n","remote: Enumerating objects: 104, done.\u001b[K\n","remote: Counting objects:   0% (1/104)\u001b[K\rremote: Counting objects:   1% (2/104)\u001b[K\rremote: Counting objects:   2% (3/104)\u001b[K\rremote: Counting objects:   3% (4/104)\u001b[K\rremote: Counting objects:   4% (5/104)\u001b[K\rremote: Counting objects:   5% (6/104)\u001b[K\rremote: Counting objects:   6% (7/104)\u001b[K\rremote: Counting objects:   7% (8/104)\u001b[K\rremote: Counting objects:   8% (9/104)\u001b[K\rremote: Counting objects:   9% (10/104)\u001b[K\rremote: Counting objects:  10% (11/104)\u001b[K\rremote: Counting objects:  11% (12/104)\u001b[K\rremote: Counting objects:  12% (13/104)\u001b[K\rremote: Counting objects:  13% (14/104)\u001b[K\rremote: Counting objects:  14% (15/104)\u001b[K\rremote: Counting objects:  15% (16/104)\u001b[K\rremote: Counting objects:  16% (17/104)\u001b[K\rremote: Counting objects:  17% (18/104)\u001b[K\rremote: Counting objects:  18% (19/104)\u001b[K\rremote: Counting objects:  19% (20/104)\u001b[K\rremote: Counting objects:  20% (21/104)\u001b[K\rremote: Counting objects:  21% (22/104)\u001b[K\rremote: Counting objects:  22% (23/104)\u001b[K\rremote: Counting objects:  23% (24/104)\u001b[K\rremote: Counting objects:  24% (25/104)\u001b[K\rremote: Counting objects:  25% (26/104)\u001b[K\rremote: Counting objects:  26% (28/104)\u001b[K\rremote: Counting objects:  27% (29/104)\u001b[K\rremote: Counting objects:  28% (30/104)\u001b[K\rremote: Counting objects:  29% (31/104)\u001b[K\rremote: Counting objects:  30% (32/104)\u001b[K\rremote: Counting objects:  31% (33/104)\u001b[K\rremote: Counting objects:  32% (34/104)\u001b[K\rremote: Counting objects:  33% (35/104)\u001b[K\rremote: Counting objects:  34% (36/104)\u001b[K\rremote: Counting objects:  35% (37/104)\u001b[K\rremote: Counting objects:  36% (38/104)\u001b[K\rremote: Counting objects:  37% (39/104)\u001b[K\rremote: Counting objects:  38% (40/104)\u001b[K\rremote: Counting objects:  39% (41/104)\u001b[K\rremote: Counting objects:  40% (42/104)\u001b[K\rremote: Counting objects:  41% (43/104)\u001b[K\rremote: Counting objects:  42% (44/104)\u001b[K\rremote: Counting objects:  43% (45/104)\u001b[K\rremote: Counting objects:  44% (46/104)\u001b[K\rremote: Counting objects:  45% (47/104)\u001b[K\rremote: Counting objects:  46% (48/104)\u001b[K\rremote: Counting objects:  47% (49/104)\u001b[K\rremote: Counting objects:  48% (50/104)\u001b[K\rremote: Counting objects:  49% (51/104)\u001b[K\rremote: Counting objects:  50% (52/104)\u001b[K\rremote: Counting objects:  51% (54/104)\u001b[K\rremote: Counting objects:  52% (55/104)\u001b[K\rremote: Counting objects:  53% (56/104)\u001b[K\rremote: Counting objects:  54% (57/104)\u001b[K\rremote: Counting objects:  55% (58/104)\u001b[K\rremote: Counting objects:  56% (59/104)\u001b[K\rremote: Counting objects:  57% (60/104)\u001b[K\rremote: Counting objects:  58% (61/104)\u001b[K\rremote: Counting objects:  59% (62/104)\u001b[K\rremote: Counting objects:  60% (63/104)\u001b[K\rremote: Counting objects:  61% (64/104)\u001b[K\rremote: Counting objects:  62% (65/104)\u001b[K\rremote: Counting objects:  63% (66/104)\u001b[K\rremote: Counting objects:  64% (67/104)\u001b[K\rremote: Counting objects:  65% (68/104)\u001b[K\rremote: Counting objects:  66% (69/104)\u001b[K\rremote: Counting objects:  67% (70/104)\u001b[K\rremote: Counting objects:  68% (71/104)\u001b[K\rremote: Counting objects:  69% (72/104)\u001b[K\rremote: Counting objects:  70% (73/104)\u001b[K\rremote: Counting objects:  71% (74/104)\u001b[K\rremote: Counting objects:  72% (75/104)\u001b[K\rremote: Counting objects:  73% (76/104)\u001b[K\rremote: Counting objects:  74% (77/104)\u001b[K\rremote: Counting objects:  75% (78/104)\u001b[K\rremote: Counting objects:  76% (80/104)\u001b[K\rremote: Counting objects:  77% (81/104)\u001b[K\rremote: Counting objects:  78% (82/104)\u001b[K\rremote: Counting objects:  79% (83/104)\u001b[K\rremote: Counting objects:  80% (84/104)\u001b[K\rremote: Counting objects:  81% (85/104)\u001b[K\rremote: Counting objects:  82% (86/104)\u001b[K\rremote: Counting objects:  83% (87/104)\u001b[K\rremote: Counting objects:  84% (88/104)\u001b[K\rremote: Counting objects:  85% (89/104)\u001b[K\rremote: Counting objects:  86% (90/104)\u001b[K\rremote: Counting objects:  87% (91/104)\u001b[K\rremote: Counting objects:  88% (92/104)\u001b[K\rremote: Counting objects:  89% (93/104)\u001b[K\rremote: Counting objects:  90% (94/104)\u001b[K\rremote: Counting objects:  91% (95/104)\u001b[K\rremote: Counting objects:  92% (96/104)\u001b[K\rremote: Counting objects:  93% (97/104)\u001b[K\rremote: Counting objects:  94% (98/104)\u001b[K\rremote: Counting objects:  95% (99/104)\u001b[K\rremote: Counting objects:  96% (100/104)\u001b[K\rremote: Counting objects:  97% (101/104)\u001b[K\rremote: Counting objects:  98% (102/104)\u001b[K\rremote: Counting objects:  99% (103/104)\u001b[K\rremote: Counting objects: 100% (104/104)\u001b[K\rremote: Counting objects: 100% (104/104), done.\u001b[K\n","remote: Compressing objects:   1% (1/70)\u001b[K\rremote: Compressing objects:   2% (2/70)\u001b[K\rremote: Compressing objects:   4% (3/70)\u001b[K\rremote: Compressing objects:   5% (4/70)\u001b[K\rremote: Compressing objects:   7% (5/70)\u001b[K\rremote: Compressing objects:   8% (6/70)\u001b[K\rremote: Compressing objects:  10% (7/70)\u001b[K\rremote: Compressing objects:  11% (8/70)\u001b[K\rremote: Compressing objects:  12% (9/70)\u001b[K\rremote: Compressing objects:  14% (10/70)\u001b[K\rremote: Compressing objects:  15% (11/70)\u001b[K\rremote: Compressing objects:  17% (12/70)\u001b[K\rremote: Compressing objects:  18% (13/70)\u001b[K\rremote: Compressing objects:  20% (14/70)\u001b[K\rremote: Compressing objects:  21% (15/70)\u001b[K\rremote: Compressing objects:  22% (16/70)\u001b[K\rremote: Compressing objects:  24% (17/70)\u001b[K\rremote: Compressing objects:  25% (18/70)\u001b[K\rremote: Compressing objects:  27% (19/70)\u001b[K\rremote: Compressing objects:  28% (20/70)\u001b[K\rremote: Compressing objects:  30% (21/70)\u001b[K\rremote: Compressing objects:  31% (22/70)\u001b[K\rremote: Compressing objects:  32% (23/70)\u001b[K\rremote: Compressing objects:  34% (24/70)\u001b[K\rremote: Compressing objects:  35% (25/70)\u001b[K\rremote: Compressing objects:  37% (26/70)\u001b[K\rremote: Compressing objects:  38% (27/70)\u001b[K\rremote: Compressing objects:  40% (28/70)\u001b[K\rremote: Compressing objects:  41% (29/70)\u001b[K\rremote: Compressing objects:  42% (30/70)\u001b[K\rremote: Compressing objects:  44% (31/70)\u001b[K\rremote: Compressing objects:  45% (32/70)\u001b[K\rremote: Compressing objects:  47% (33/70)\u001b[K\rremote: Compressing objects:  48% (34/70)\u001b[K\rremote: Compressing objects:  50% (35/70)\u001b[K\rremote: Compressing objects:  51% (36/70)\u001b[K\rremote: Compressing objects:  52% (37/70)\u001b[K\rremote: Compressing objects:  54% (38/70)\u001b[K\rremote: Compressing objects:  55% (39/70)\u001b[K\rremote: Compressing objects:  57% (40/70)\u001b[K\rremote: Compressing objects:  58% (41/70)\u001b[K\rremote: Compressing objects:  60% (42/70)\u001b[K\rremote: Compressing objects:  61% (43/70)\u001b[K\rremote: Compressing objects:  62% (44/70)\u001b[K\rremote: Compressing objects:  64% (45/70)\u001b[K\rremote: Compressing objects:  65% (46/70)\u001b[K\rremote: Compressing objects:  67% (47/70)\u001b[K\rremote: Compressing objects:  68% (48/70)\u001b[K\rremote: Compressing objects:  70% (49/70)\u001b[K\rremote: Compressing objects:  71% (50/70)\u001b[K\rremote: Compressing objects:  72% (51/70)\u001b[K\rremote: Compressing objects:  74% (52/70)\u001b[K\rremote: Compressing objects:  75% (53/70)\u001b[K\rremote: Compressing objects:  77% (54/70)\u001b[K\rremote: Compressing objects:  78% (55/70)\u001b[K\rremote: Compressing objects:  80% (56/70)\u001b[K\rremote: Compressing objects:  81% (57/70)\u001b[K\rremote: Compressing objects:  82% (58/70)\u001b[K\rremote: Compressing objects:  84% (59/70)\u001b[K\rremote: Compressing objects:  85% (60/70)\u001b[K\rremote: Compressing objects:  87% (61/70)\u001b[K\rremote: Compressing objects:  88% (62/70)\u001b[K\rremote: Compressing objects:  90% (63/70)\u001b[K\rremote: Compressing objects:  91% (64/70)\u001b[K\rremote: Compressing objects:  92% (65/70)\u001b[K\rremote: Compressing objects:  94% (66/70)\u001b[K\rremote: Compressing objects:  95% (67/70)\u001b[K\rremote: Compressing objects:  97% (68/70)\u001b[K\rremote: Compressing objects:  98% (69/70)\u001b[K\rremote: Compressing objects: 100% (70/70)\u001b[K\rremote: Compressing objects: 100% (70/70), done.\u001b[K\n","Receiving objects:   0% (1/104)\rReceiving objects:   1% (2/104)\rReceiving objects:   2% (3/104)\rReceiving objects:   3% (4/104)\rReceiving objects:   4% (5/104)\rReceiving objects:   5% (6/104)\rReceiving objects:   6% (7/104)\rReceiving objects:   7% (8/104)\rReceiving objects:   8% (9/104)\rReceiving objects:   9% (10/104)\rReceiving objects:  10% (11/104)\rReceiving objects:  11% (12/104)\rReceiving objects:  12% (13/104)\rReceiving objects:  13% (14/104)\rReceiving objects:  14% (15/104)\rReceiving objects:  15% (16/104)\rReceiving objects:  16% (17/104)\rReceiving objects:  17% (18/104)\rReceiving objects:  18% (19/104)\rReceiving objects:  19% (20/104)\rReceiving objects:  20% (21/104)\rReceiving objects:  21% (22/104)\rReceiving objects:  22% (23/104)\rReceiving objects:  23% (24/104)\rReceiving objects:  24% (25/104)\rReceiving objects:  25% (26/104)\rReceiving objects:  26% (28/104)\rReceiving objects:  27% (29/104)\rremote: Total 104 (delta 51), reused 80 (delta 33), pack-reused 0\u001b[K\n","Receiving objects: 100% (104/104), 784.94 KiB | 16.70 MiB/s, done.\n","Resolving deltas: 100% (51/51), done.\n"]}]},{"cell_type":"code","source":["cd finetune-embedding\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2b4PUwMmFZ2C","executionInfo":{"status":"ok","timestamp":1693309309759,"user_tz":-330,"elapsed":5,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"e1b918ac-99f6-4192-da18-07376c741426"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/finetune-embedding\n"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Sd81knBGUGO","executionInfo":{"status":"ok","timestamp":1693309316947,"user_tz":-330,"elapsed":431,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"0d78b599-6d64-40b3-ba2e-220b917aad05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/finetune-embedding\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2s_VHsQEGTeV","executionInfo":{"status":"ok","timestamp":1693309353521,"user_tz":-330,"elapsed":23481,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"25fe4f58-ae45-4099-fce0-7aacf947e0b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-index==0.8.5.post2 (from -r requirements.txt (line 1))\n","  Downloading llama_index-0.8.5.post2-py3-none-any.whl (686 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/686.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/686.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m686.8/686.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentence-transformers==2.2.2 (from -r requirements.txt (line 2))\n","  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tiktoken (from llama-index==0.8.5.post2->-r requirements.txt (line 1))\n","  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dataclasses-json (from llama-index==0.8.5.post2->-r requirements.txt (line 1))\n","  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n","Collecting langchain<=0.0.266,>=0.0.262 (from llama-index==0.8.5.post2->-r requirements.txt (line 1))\n","  Downloading langchain-0.0.266-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sqlalchemy>=2.0.15 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.8.5.post2->-r requirements.txt (line 1)) (2.0.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index==0.8.5.post2->-r requirements.txt (line 1)) (1.23.5)\n","Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.8.5.post2->-r requirements.txt (line 1)) (8.2.3)\n","Collecting openai>=0.26.4 (from llama-index==0.8.5.post2->-r requirements.txt (line 1))\n","  Downloading openai-0.27.9-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index==0.8.5.post2->-r requirements.txt (line 1)) (1.5.3)\n","Collecting urllib3<2 (from llama-index==0.8.5.post2->-r requirements.txt (line 1))\n","  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.8.5.post2->-r requirements.txt (line 1)) (2023.6.0)\n","Collecting typing-inspect>=0.8.0 (from llama-index==0.8.5.post2->-r requirements.txt (line 1))\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.8.5.post2->-r requirements.txt (line 1)) (4.7.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.8.5.post2->-r requirements.txt (line 1)) (4.11.2)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from llama-index==0.8.5.post2->-r requirements.txt (line 1)) (1.5.7)\n","Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers==2.2.2->-r requirements.txt (line 2))\n","  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 2)) (4.66.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 2)) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 2)) (0.15.2+cu118)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 2)) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 2)) (1.10.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 2)) (3.8.1)\n","Collecting sentencepiece (from sentence-transformers==2.2.2->-r requirements.txt (line 2))\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers==2.2.2->-r requirements.txt (line 2))\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (3.12.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (6.0.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (23.1)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (3.8.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (4.0.3)\n","Collecting langsmith<0.1.0,>=0.0.21 (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5.post2->-r requirements.txt (line 1))\n","  Downloading langsmith-0.0.27-py3-none-any.whl (34 kB)\n","Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (2.8.5)\n","Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5.post2->-r requirements.txt (line 1))\n","  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic<2,>=1 (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5.post2->-r requirements.txt (line 1))\n","  Downloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index==0.8.5.post2->-r requirements.txt (line 1))\n","  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.15->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (2.0.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (16.0.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (2023.6.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2))\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2))\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index==0.8.5.post2->-r requirements.txt (line 1))\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (2.4.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (2023.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (3.2.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (9.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index==0.8.5.post2->-r requirements.txt (line 1)) (1.16.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 2)) (1.3.0)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=150f88fba41d614ad6497797c90589a6377f6f97d0fb9c817cd7e970e8016583\n","  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n","Successfully built sentence-transformers\n","Installing collected packages: tokenizers, sentencepiece, safetensors, urllib3, pydantic, mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, tiktoken, openai, langsmith, huggingface-hub, dataclasses-json, transformers, langchain, llama-index, sentence-transformers\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.0.4\n","    Uninstalling urllib3-2.0.4:\n","      Successfully uninstalled urllib3-2.0.4\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.2.1\n","    Uninstalling pydantic-2.2.1:\n","      Successfully uninstalled pydantic-2.2.1\n","Successfully installed dataclasses-json-0.5.14 huggingface-hub-0.16.4 langchain-0.0.266 langsmith-0.0.27 llama-index-0.8.5.post2 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.27.9 openapi-schema-pydantic-1.2.4 pydantic-1.10.12 safetensors-0.3.3 sentence-transformers-2.2.2 sentencepiece-0.1.99 tiktoken-0.4.0 tokenizers-0.13.3 transformers-4.32.1 typing-inspect-0.9.0 urllib3-1.26.16\n"]}]},{"cell_type":"code","source":["import json\n","\n","from llama_index import SimpleDirectoryReader\n","from llama_index.node_parser import SimpleNodeParser\n","from llama_index.schema import MetadataMode"],"metadata":{"id":"Yh6b4V1pOT5B","executionInfo":{"status":"ok","timestamp":1693311390633,"user_tz":-330,"elapsed":440,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["cd /content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IljkKhjoOXE9","executionInfo":{"status":"ok","timestamp":1693311407260,"user_tz":-330,"elapsed":435,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"27844de1-e278-4abb-c8a0-9e3828468332"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["ls llama_index/docs/examples/data/10k"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrMM9nweOvMI","executionInfo":{"status":"ok","timestamp":1693311545724,"user_tz":-330,"elapsed":429,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"fe14da65-a85a-486a-f1b6-8e822fe62e66"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["lyft_2021.pdf  uber_2021.pdf\n"]}]},{"cell_type":"code","source":["ls /content/finetune-embedding"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VrG5gQWAPJfw","executionInfo":{"status":"ok","timestamp":1693311676089,"user_tz":-330,"elapsed":1486,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"f775abce-cd6a-4c6b-911b-8da9be2a5be4"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/           \u001b[01;34mexp_finetune\u001b[0m/   generate_dataset.ipynb  requirements.txt\n","evaluate.ipynb  finetune.ipynb  README.md               \u001b[01;34mresults\u001b[0m/\n"]}]},{"cell_type":"code","source":["TRAIN_FILES = ['./llama_index/docs/examples/data/10k/lyft_2021.pdf']\n","VAL_FILES = ['./llama_index/docs/examples/data/10k/uber_2021.pdf']\n","\n","TRAIN_CORPUS_FPATH = './finetune-embedding/data/train_corpus.json'\n","VAL_CORPUS_FPATH = './finetune-embedding/data/val_corpus.json'\n","\n","def load_corpus(files, verbose=False):\n","    if verbose:\n","        print(f\"Loading files {files}\")\n","\n","    reader = SimpleDirectoryReader(input_files=files)\n","    docs = reader.load_data()\n","    if verbose:\n","        print(f'Loaded {len(docs)} docs')\n","\n","    parser = SimpleNodeParser.from_defaults()\n","    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)\n","\n","    if verbose:\n","        print(f'Parsed {len(nodes)} nodes')\n","\n","    corpus = {node.node_id: node.get_content(metadata_mode=MetadataMode.NONE) for node in nodes}\n","    return corpus\n"],"metadata":{"id":"wxZ4fxE8Odjz","executionInfo":{"status":"ok","timestamp":1693311759094,"user_tz":-330,"elapsed":5,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["!pip install pypdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zW3clrrlPzmA","executionInfo":{"status":"ok","timestamp":1693311848850,"user_tz":-330,"elapsed":6770,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"0f0e5210-2e8b-4ed6-e651-681dd74879ca"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pypdf\n","  Downloading pypdf-3.15.4-py3-none-any.whl (272 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdf\n","Successfully installed pypdf-3.15.4\n"]}]},{"cell_type":"code","source":["train_corpus = load_corpus(TRAIN_FILES, verbose=True)\n","val_corpus = load_corpus(VAL_FILES, verbose=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226,"referenced_widgets":["0390966c709b4a15a92a0cd13acb374b","c245bb3925cc4c59b850c7153c8e6f31","2cb0cf03310a4e689d3190e1007be43b","6802f96bc5ef46d484e4554100187075","8dad215942d6485f991749d19ede3473","90896cd70a984bbea18b7441b8924262","39de88493f334050ae78e4827c59d545","e8bb7710b2264612a08e587f39b886d9","1e92218332f44865a04f0b0a6ddf4788","360918537e124950b33f24d6eb66a7b9","5270af6fd9944d2f9fb6b0daebcdd3de","f9f91737dc5d4abc86d767374279caad","36349cf3841c4236b6759ea69d353bb6","d3c8e46d2ed543a48f2c860aeba95cdb","ef3b1ca40fb34644a2230a2f64ea3326","7429185a4ff04dbcb1681da88deb0038","84ba55587f20495aafc35f639403b16f","81af2e25d01e487793c6058c4d16cdba","368295407d0643349f17b955fe5a72fd","3f773de2fa4244b28720db3dcd18c785","39062f243b5a449db48af21cd4d84c89","40a7fde3b39e4bbb8313b7c4079ab6d0"]},"id":"LxFrJR6rOmMy","executionInfo":{"status":"ok","timestamp":1693311888279,"user_tz":-330,"elapsed":35897,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"44d161dc-b6c0-41a4-ee0d-3e8b5baf34d3"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading files ['./llama_index/docs/examples/data/10k/lyft_2021.pdf']\n","Loaded 238 docs\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /tmp/llama_index...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"display_data","data":{"text/plain":["Parsing documents into nodes:   0%|          | 0/238 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0390966c709b4a15a92a0cd13acb374b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Parsed 334 nodes\n","Loading files ['./llama_index/docs/examples/data/10k/uber_2021.pdf']\n","Loaded 307 docs\n"]},{"output_type":"display_data","data":{"text/plain":["Parsing documents into nodes:   0%|          | 0/307 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9f91737dc5d4abc86d767374279caad"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Parsed 395 nodes\n"]}]},{"cell_type":"code","source":["len(train_corpus)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KJXfmpshki7","executionInfo":{"status":"ok","timestamp":1693316439571,"user_tz":-330,"elapsed":419,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"2f1df2e5-15e2-4c32-b574-06e7e188197f"},"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["334"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["for k,v in train_corpus.items():\n","  print(train_corpus[k])\n","  break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ki5L4D7Agdqi","executionInfo":{"status":"ok","timestamp":1693316508031,"user_tz":-330,"elapsed":471,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"38cd9c79-4fc8-45e7-c04c-427c5dd1fcdb"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["UNITED STATESSECURITIES AND EXCHANGE COMMISSIONWashington, D.C. 20549FORM 10-K (Mark One)☒ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934For the fiscal year ended December 31, 2021OR☐TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 FOR THE TRANSITION PERIODFROM                      TOCommission File Number 001-38846Lyft, Inc.(Exact name of Registrant as specified in its Charter)Delaware20-8809830(State or other jurisdiction ofincorporation or organization)(I.R.S. EmployerIdentification No.)185 Berry Street, Suite 5000San Francisco, California94107(Address of principal executive offices)(Zip Code)Registrant’s telephone number, including area code: (844) 250-2773Securities registered pursuant to Section 12(b) of the Act: Title of each classTradingSymbol(s)Name of each exchange on which registeredClass A common stock, par value of $0.00001 per shareLYFTNasdaq Global Select MarketSecurities registered pursuant to Section 12(g) of the Act: NoneIndicate by check mark if the Registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. Yes ☒ No ☐Indicate by check mark if the Registrant is not required to file reports pursuant to Section 13 or 15(d) of the Act.  Yes ☐ No ☒Indicate by check mark whether the Registrant: (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months (or for suchshorter period that the Registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days.  Yes ☒ No ☐Indicate by check mark whether the Registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation S-T (§232.405 of this chapter) duringthe preceding 12 months (or for such shorter period that the Registrant was required to submit such files).  Yes ☒ No ☐Indicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, smaller reporting company, or an emerging growth company. See the definitions of“large accelerated filer,” “accelerated filer,” “smaller reporting company,” and “emerging growth company” in Rule 12b-2 of the Exchange Act.Large accelerated filer☒Accelerated filer☐Non-accelerated filer☐Smaller reporting company☐Emerging growth company☐If an emerging growth company, indicate by check mark if the registrant has elected not to use the extended transition period for complying with any new or revised financial accounting standardsprovided pursuant to Section 13(a) of the Exchange Act.  ☐Indicate by check mark whether the registrant has filed a report on and attestation to its management’s assessment of the effectiveness of its internal control over financial reporting under Section 404(b)of the Sarbanes-Oxley Act (15 U.S.C. 7262(b)) by the registered public accounting firm that prepared or issued its audit report. ☒Indicate by check mark whether the Registrant is a shell company (as defined in Rule 12b-2 of the Exchange Act).  Yes ☐ No ☒The aggregate market value of the Registrant’s common stock held by non-affiliates of the Registrant on June 30, 2021, the last business day of its most recently completed second fiscal quarter, was$19.6 billion based on the closing sales price of the Registrant’s Class A common stock on that date.On February 22, 2022, the Registrant had 339,954,714 shares of Class A common stock and 8,602,629 shares of Class B common stock outstanding.DOCUMENTS INCORPORATED BY REFERENCEPortions of the registrant’s Proxy Statement for the 2022 Annual Meeting of Stockholders are incorporated herein by reference in Part III of this Annual Report on Form 10-K to the extent stated herein.Such proxy statement will be filed with the Securities and Exchange Commission within 120 days of the registrant’s fiscal year ended December 31, 2021.\n"]}]},{"cell_type":"code","source":["with open(TRAIN_CORPUS_FPATH, 'w+') as f:\n","    json.dump(train_corpus, f)\n","\n","with open(VAL_CORPUS_FPATH, 'w+') as f:\n","    json.dump(val_corpus, f)"],"metadata":{"id":"tH8IMRFnQUy7","executionInfo":{"status":"ok","timestamp":1693311974149,"user_tz":-330,"elapsed":415,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["import re\n","import uuid\n","\n","from llama_index.llms import OpenAI\n","from llama_index.schema import MetadataMode\n","from tqdm.notebook import tqdm"],"metadata":{"id":"e4QWPOnZQinb","executionInfo":{"status":"ok","timestamp":1693311977178,"user_tz":-330,"elapsed":4,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["TRAIN_QUERIES_FPATH = './data/train_queries.json'\n","TRAIN_RELEVANT_DOCS_FPATH = './data/train_relevant_docs.json'\n","\n","VAL_QUERIES_FPATH = './data/val_queries.json'\n","VAL_RELEVANT_DOCS_FPATH = './data/val_relevant_docs.json'\n"],"metadata":{"id":"QqvSG2baQnpq","executionInfo":{"status":"ok","timestamp":1693312021899,"user_tz":-330,"elapsed":667,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["with open(TRAIN_CORPUS_FPATH, 'r+') as f:\n","    train_corpus = json.load(f)\n","\n","with open(VAL_CORPUS_FPATH, 'r+') as f:\n","    val_corpus = json.load(f)"],"metadata":{"id":"xeXhTkPVQtEY","executionInfo":{"status":"ok","timestamp":1693312025024,"user_tz":-330,"elapsed":672,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["def generate_queries(\n","    corpus,\n","    num_questions_per_chunk=2,\n","    prompt_template=None,\n","    verbose=False,\n","):\n","    \"\"\"\n","    Automatically generate hypothetical questions that could be answered with\n","    doc in the corpus.\n","    \"\"\"\n","    llm = OpenAI(model='gpt-3.5-turbo')\n","\n","    prompt_template = prompt_template or \"\"\"\\\n","    Context information is below.\n","\n","    ---------------------\n","    {context_str}\n","    ---------------------\n","\n","    Given the context information and not prior knowledge.\n","    generate only questions based on the below query.\n","\n","    You are a Teacher/ Professor. Your task is to setup \\\n","    {num_questions_per_chunk} questions for an upcoming \\\n","    quiz/examination. The questions should be diverse in nature \\\n","    across the document. Restrict the questions to the \\\n","    context information provided.\"\n","    \"\"\"\n","\n","    queries = {}\n","    relevant_docs = {}\n","    for node_id, text in tqdm(corpus.items()):\n","        query = prompt_template.format(context_str=text, num_questions_per_chunk=num_questions_per_chunk)\n","        response = llm.complete(query)\n","\n","        result = str(response).strip().split(\"\\n\")\n","        questions = [\n","            re.sub(r\"^\\d+[\\).\\s]\", \"\", question).strip() for question in result\n","        ]\n","        questions = [question for question in questions if len(question) > 0]\n","\n","        for question in questions:\n","            question_id = str(uuid.uuid4())\n","            queries[question_id] = question\n","            relevant_docs[question_id] = [node_id]\n","    return queries, relevant_docs"],"metadata":{"id":"ViWHY0T8Q1bo","executionInfo":{"status":"ok","timestamp":1693312051394,"user_tz":-330,"elapsed":407,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["train_queries, train_relevant_docs = generate_queries(train_corpus)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"G6eJZXYEQ8tn","executionInfo":{"status":"error","timestamp":1693312080483,"user_tz":-330,"elapsed":530,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"50ecab99-b44d-46a8-eee2-f2ffb6fcf3f4"},"execution_count":44,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-f8c39bc0c526>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_relevant_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_queries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-43-925301a2742a>\u001b[0m in \u001b[0;36mgenerate_queries\u001b[0;34m(corpus, num_questions_per_chunk, prompt_template, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpt-3.5-turbo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     prompt_template = prompt_template or \"\"\"\\\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/llms/openai.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, temperature, max_tokens, additional_kwargs, max_retries, api_key, api_type, callback_manager, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     ) -> None:\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mvalidate_openai_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0madditional_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madditional_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/llms/openai_utils.py\u001b[0m in \u001b[0;36mvalidate_openai_api_key\u001b[0;34m(api_key, api_type)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopenai_api_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMISSING_API_KEY_ERROR_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     elif (\n\u001b[1;32m    270\u001b[0m         \u001b[0mopenai_api_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"open_ai\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: No API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n"]}]},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","# %% [markdown]\n","### Generate synthetic queries\n","\n","\n","# %% [markdown]\n","Now, we use an LLM (gpt-3.5-turbo) to generate questions using each text chunk in the corpus as context.\n","\n","Each pair of (generated question, text chunk used as context) becomes a datapoint in the finetuning dataset (either for training or evaluation).\n","\n","Code cell <undefined>\n","# %% [code]\n","\n","\n","Code cell <undefined>\n","# %% [code]\n","\n","Code cell <undefined>\n","# %% [code]\n","\n","\n","Code cell <undefined>\n","# %% [code]\n","\n","\n","Code cell <undefined>\n","# %% [code]\n","\n","Execution output\n","0KB\n","\ttext/plain\n","\t\t0%|          | 0/334 [00:00<?, ?it/s]\n","\n","Code cell <undefined>\n","# %% [code]\n","val_queries, val_relevant_docs = generate_queries(val_corpus)\n","Execution output\n","0KB\n","\ttext/plain\n","\t\t0%|          | 0/395 [00:00<?, ?it/s]\n","\n","Code cell <undefined>\n","# %% [code]\n","with open(TRAIN_QUERIES_FPATH, 'w+') as f:\n","    json.dump(train_queries, f)\n","\n","with open(TRAIN_RELEVANT_DOCS_FPATH, 'w+') as f:\n","    json.dump(train_relevant_docs, f)\n","\n","with open(VAL_QUERIES_FPATH, 'w+') as f:\n","    json.dump(val_queries, f)\n","\n","with open(VAL_RELEVANT_DOCS_FPATH, 'w+') as f:\n","    json.dump(val_relevant_docs, f)\n","\n","\n","# %% [markdown]\n","### Merge data\n","\n","\n","# %% [markdown]\n","Finally, we do some minor re-organization to make it easier to access the dataset for training and evaluation.\n","\n","Code cell <undefined>\n","# %% [code]\n","TRAIN_DATASET_FPATH = './data/train_dataset.json'\n","VAL_DATASET_FPATH = './data/val_dataset.json'\n","\n","Code cell <undefined>\n","# %% [code]\n","train_dataset = {\n","    'queries': train_queries,\n","    'corpus': train_corpus,\n","    'relevant_docs': train_relevant_docs,\n","}\n","\n","val_dataset = {\n","    'queries': val_queries,\n","    'corpus': val_corpus,\n","    'relevant_docs': val_relevant_docs,\n","}\n","\n","Code cell <undefined>\n","# %% [code]\n","with open(TRAIN_DATASET_FPATH, 'w+') as f:\n","    json.dump(train_dataset, f)\n","\n","with open(VAL_DATASET_FPATH, 'w+') as f:\n","    json.dump(val_dataset, f)\n"],"metadata":{"id":"hwg6yNLIKNZl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5VhJKY8EUCrH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iC5jZyjBUCjU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","from tqdm.notebook import tqdm\n","import pandas as pd\n","\n","from llama_index import ServiceContext, VectorStoreIndex\n","from llama_index.schema import TextNode\n","from llama_index.embeddings import OpenAIEmbedding"],"metadata":{"id":"J5RXO0bPUCfb","executionInfo":{"status":"ok","timestamp":1693312892826,"user_tz":-330,"elapsed":430,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["cd /content/finetune-embedding/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FGaMz8ZQULzl","executionInfo":{"status":"ok","timestamp":1693313049500,"user_tz":-330,"elapsed":470,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"a2879034-777c-42c5-dbd8-7ceb57ae2630"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/finetune-embedding\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W3E27fVBUoHN","executionInfo":{"status":"ok","timestamp":1693313055897,"user_tz":-330,"elapsed":429,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"9161cdba-c321-4dbd-e0cf-55c5d6f8783c"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/           \u001b[01;34mexp_finetune\u001b[0m/   generate_dataset.ipynb  requirements.txt\n","evaluate.ipynb  finetune.ipynb  README.md               \u001b[01;34mresults\u001b[0m/\n"]}]},{"cell_type":"code","source":["TRAIN_DATASET_FPATH = './data/train_dataset.json'\n","VAL_DATASET_FPATH = './data/val_dataset.json'"],"metadata":{"id":"Nth_L7AaUHw6","executionInfo":{"status":"ok","timestamp":1693313059149,"user_tz":-330,"elapsed":3,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["with open(TRAIN_DATASET_FPATH, 'r+') as f:\n","    train_dataset = json.load(f)\n","\n","with open(VAL_DATASET_FPATH, 'r+') as f:\n","    val_dataset = json.load(f)"],"metadata":{"id":"z4Ma-b12UvcN","executionInfo":{"status":"ok","timestamp":1693313074368,"user_tz":-330,"elapsed":441,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["def evaluate(\n","    dataset,\n","    embed_model,\n","    top_k=5,\n","    verbose=False,\n","):\n","    corpus = dataset['corpus']\n","    queries = dataset['queries']\n","    relevant_docs = dataset['relevant_docs']\n","\n","    service_context = ServiceContext.from_defaults(embed_model=embed_model)\n","    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]\n","    index = VectorStoreIndex(\n","        nodes,\n","        service_context=service_context,\n","        show_progress=True\n","    )\n","    retriever = index.as_retriever(similarity_top_k=top_k)\n","\n","    eval_results = []\n","    for query_id, query in tqdm(queries.items()):\n","        retrieved_nodes = retriever.retrieve(query)\n","        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n","        expected_id = relevant_docs[query_id][0]\n","        is_hit = expected_id in retrieved_ids  # assume 1 relevant doc\n","\n","        eval_result = {\n","            'is_hit': is_hit,\n","            'retrieved': retrieved_ids,\n","            'expected': expected_id,\n","            'query': query_id,\n","        }\n","        eval_results.append(eval_result)\n","    return eval_results"],"metadata":{"id":"mWpfX5AmUzb4","executionInfo":{"status":"ok","timestamp":1693313091685,"user_tz":-330,"elapsed":495,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["from sentence_transformers.evaluation import InformationRetrievalEvaluator\n","from sentence_transformers import SentenceTransformer\n","\n","def evaluate_st(\n","    dataset,\n","    model_id,\n","    name,\n","):\n","    corpus = dataset['corpus']\n","    queries = dataset['queries']\n","    relevant_docs = dataset['relevant_docs']\n","\n","    evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs, name=name)\n","    model = SentenceTransformer(model_id)\n","    return evaluator(model, output_path='results/')"],"metadata":{"id":"sknzA4TqU3Cy","executionInfo":{"status":"ok","timestamp":1693313112549,"user_tz":-330,"elapsed":6671,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["ada = OpenAIEmbedding()\n","ada_val_results = evaluate(val_dataset, ada)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"xBo4PEJFWAoj","executionInfo":{"status":"error","timestamp":1693313407371,"user_tz":-330,"elapsed":552,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"0a45fac5-2547-43f8-827d-a8b1af37c6aa"},"execution_count":56,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-c3fde0df70f2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mada_val_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mada\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/embeddings/openai.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, model, deployment_name, embed_batch_size, callback_manager, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# or OPENAI_API_KEY env variable are set to a valid key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# Raises ValueError if missing or doesn't match valid format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         validate_openai_api_key(\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"api_key\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"api_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/llms/openai_utils.py\u001b[0m in \u001b[0;36mvalidate_openai_api_key\u001b[0;34m(api_key, api_type)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopenai_api_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMISSING_API_KEY_ERROR_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     elif (\n\u001b[1;32m    270\u001b[0m         \u001b[0mopenai_api_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"open_ai\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: No API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n"]}]}]}